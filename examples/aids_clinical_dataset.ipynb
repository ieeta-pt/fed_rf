{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install fed_rf_mk package\n",
    "\n",
    "Package available at: https://pypi.org/project/fed-rf-mk/\n",
    "\n",
    "Uncomment the following line to install the package\n",
    "\n",
    "The usage of a virtual environment is recommended. ``python -m venv venv`` then ``source venv/bin/activate``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install fed-rf-mk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the aids clinical trial dataset from ucirepo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fetch dataset\n",
    "aids_clinical_trials_group_study_175 = fetch_ucirepo(id=890)\n",
    "\n",
    "# Extract data\n",
    "X = aids_clinical_trials_group_study_175.data.features  # Features DataFrame\n",
    "y = aids_clinical_trials_group_study_175.data.targets  # Target DataFrame\n",
    "\n",
    "# Debug: Print available column names\n",
    "print(\"Features (X) columns:\", X.columns.tolist())\n",
    "print(\"Target (y) columns:\", y.columns.tolist())\n",
    "\n",
    "# Ensure 'cid' is in y\n",
    "if \"cid\" not in y.columns:\n",
    "    print(\"Error: 'cid' column is missing from the target DataFrame!\")\n",
    "    print(\"Available target columns:\", y.columns.tolist())\n",
    "    exit()\n",
    "\n",
    "# Combine X and y into a single DataFrame\n",
    "df = pd.concat([X, y], axis=1)\n",
    "all_features = [col for col in df.columns if col != 'cid']  # Exclude target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate a distributed enviroment with 3 clients.\n",
    "\n",
    "Last client is the test client and have 20% of the data.\n",
    "\n",
    "The remaining clients have 40% of the data each which will be used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Define number of partitions\n",
    "N = 3  \n",
    "TRAIN_RATIO = 0.8  # 80% for training, 20% for testing\n",
    "\n",
    "\n",
    "# Load dataset (Assuming df is already loaded and contains 'cid' column)\n",
    "df[\"cid\"].value_counts(normalize=True) * 100\n",
    "\n",
    "# Separate classes\n",
    "df_majority = df[df[\"cid\"] == 0]  # cid = 0 (majority)\n",
    "df_minority = df[df[\"cid\"] == 1]  # cid = 1 (minority)\n",
    "\n",
    "print(\"Majority class (cid=0) count:\", len(df_majority))\n",
    "print(\"Minority class (cid=1) count:\", len(df_minority))\n",
    "\n",
    "# Shuffle data for randomness\n",
    "df_majority = shuffle(df_majority, random_state=42).reset_index(drop=True)\n",
    "df_minority = shuffle(df_minority, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Split data into 80% training and 20% testing\n",
    "majority_train_size = int(len(df_majority) * TRAIN_RATIO)\n",
    "minority_train_size = int(len(df_minority) * TRAIN_RATIO)\n",
    "\n",
    "df_majority_train = df_majority.iloc[:majority_train_size]\n",
    "df_majority_test = df_majority.iloc[majority_train_size:]\n",
    "\n",
    "df_minority_train = df_minority.iloc[:minority_train_size]\n",
    "df_minority_test = df_minority.iloc[minority_train_size:]\n",
    "\n",
    "# Allocate 80% training data into N-1 partitions\n",
    "train_partitions = [[] for _ in range(N - 1)]\n",
    "\n",
    "for i in range(len(df_majority_train)):\n",
    "    train_partitions[i % (N - 1)].append(df_majority_train.iloc[i])\n",
    "\n",
    "for i in range(len(df_minority_train)):\n",
    "    train_partitions[i % (N - 1)].append(df_minority_train.iloc[i])\n",
    "\n",
    "# Convert training partitions into DataFrames\n",
    "train_partitions = [pd.DataFrame(part) for part in train_partitions]\n",
    "\n",
    "# The last partition gets the 20% test data\n",
    "test_partition = pd.concat([df_majority_test, df_minority_test]).sample(frac=1, random_state=42).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create output directory\n",
    "output_dir = \"train_datasets/aids_clinical\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save training partitions\n",
    "for i, part in enumerate(train_partitions):\n",
    "    file_path = os.path.join(output_dir, f\"part_{i}.csv\")\n",
    "    part.to_csv(file_path, index=False)\n",
    "\n",
    "    # Check file size\n",
    "    size_in_bytes = os.path.getsize(file_path)\n",
    "    size_in_megabytes = size_in_bytes / (1024 * 1024)\n",
    "\n",
    "    print(f\"\\nðŸ“Š Distribution of 'cid' in part_{i} (Training):\")\n",
    "    print(part[\"cid\"].value_counts(normalize=True) * 100)\n",
    "    print(f\"Space occupied by part_{i}: {size_in_bytes} bytes ({size_in_megabytes:.2f} MB)\")\n",
    "\n",
    "# Save the last partition as the test set\n",
    "file_path = os.path.join(output_dir, f\"part_{N-1}.csv\")\n",
    "test_partition.to_csv(file_path, index=False)\n",
    "\n",
    "# Check file size\n",
    "size_in_bytes = os.path.getsize(file_path)\n",
    "size_in_megabytes = size_in_bytes / (1024 * 1024)\n",
    "\n",
    "print(f\"\\nðŸ“Š Distribution of 'cid' in part_{N-1} (Testing):\")\n",
    "print(test_partition[\"cid\"].value_counts(normalize=True) * 100)\n",
    "print(f\"Space occupied by part_{N-1}: {size_in_bytes} bytes ({size_in_megabytes:.2f} MB)\")\n",
    "\n",
    "print(\"\\nâœ… Partitioning with 80%-20% split completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch Servers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start each datasite in a different terminal.\n",
    "\n",
    "The auto_accept function can be set to True to automatically accept requests from clients. Otherwise, each dataowner will have to accept the requests manually.\n",
    "\n",
    "The weight of each datasite can also be set. It is usefull if the datasites have different number of samples or samples with different importance. If not set, the weight is equally distributed by all training datasites.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fed_rf_mk.server import FLServer\n",
    "import threading\n",
    "\n",
    "server = FLServer(\"aids_clinical_part_0\", 8080, \"train_datasets/aids_clinical/part_0.csv\", auto_accept=False)\n",
    "server_thread = threading.Thread(target=server.start, daemon=True)\n",
    "server_thread.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "server2 = FLServer(\"aids_clinical_part_1\", 8081, \"train_datasets/aids_clinical/part_1.csv\", auto_accept=True)\n",
    "server_thread = threading.Thread(target=server2.start, daemon=True)\n",
    "server_thread.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "server3 = FLServer(\"aids_clinical_part_2\", 8082, \"train_datasets/aids_clinical/part_2.csv\", auto_accept=False)\n",
    "server_thread = threading.Thread(target=server3.start, daemon=True)\n",
    "server_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sleep time to make sure datasites are up before proceeding\n",
    "\n",
    "import time\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client Notebook\n",
    "\n",
    "With the server running, the client is initiated and connected to the datasites (2 training sites and 1 test site).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fed_rf_mk.client import FLClient\n",
    "\n",
    "rf_client = FLClient()\n",
    "\n",
    "## COnnect to N client\n",
    "for i in range(N-1):\n",
    "    port = 8080 + i\n",
    "    rf_client.add_train_client(name=f\"aids_clinical_part_{i+1}\",\n",
    "                               url=f\"http://localhost:{port}\", email=\"fedlearning@rf.com\", password=\"****\")\n",
    "\n",
    "# CONNECT EVAL CLIENT\n",
    "eval_port = 8080 + N - 1\n",
    "rf_client.add_eval_client(name=f\"aids_clinical_part_{N}\",\n",
    "    url=f\"http://localhost:{eval_port}\", email=\"fedlearning@rf.com\", password=\"****\")\n",
    "\n",
    "rf_client.add_train_client(name=\"aids_clinical_part_1\", url=\"http://localhost:8080\", email=\"fedlearning@rf.com\", password=\"****\")\n",
    "rf_client.add_train_client(name=\"aids_clinical_part_2\", url=\"http://localhost:8081\", email=\"fedlearning@rf.com\", password=\"****\")\n",
    "rf_client.add_eval_client(name=\"aids_clinical_part_3\", url=\"http://localhost:8082\", email=\"fedlearning@rf.com\", password=\"****\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specification of parameters for the training process.\n",
    "\n",
    "dataParams are the parameters involving the data treatment, such as specifying the target variable and the features to be ignored.\n",
    "\n",
    "modelParams are the parameters for the model, such as the number of initial trees, train/test size for each epoch, and the number of epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataParams = {\n",
    "    \"target\": \"cid\",\n",
    "    \"ignored_columns\": [\"cid\"]\n",
    "}\n",
    "\n",
    "modelParams = {\n",
    "    \"model\": None,\n",
    "    \"n_base_estimators\": 10,\n",
    "    \"n_incremental_estimators\": 2,\n",
    "    \"train_size\": 0.7,\n",
    "    \"test_size\": 0.5,\n",
    "    \"sample_size\": None,\n",
    "    \"fl_epochs\": 1\n",
    "}\n",
    "\n",
    "rf_client.set_data_params(dataParams)\n",
    "rf_client.set_model_params(modelParams)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After specifying the parameters, the request can be sent to the datasites and the status checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf_client.send_request()\n",
    "\n",
    "rf_client.check_status_last_code_requests()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server.list_pending_requests()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# server.inspect_request(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since datasite 1 and 3 auto_accept was set to False, the requests will have to be accepted manually using the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server.approve_request(0)\n",
    "# server2.approve_request(0)\n",
    "server3.approve_request(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After checking that all the requests have been accepted, the training can be started.\n",
    "If, for some reason, a request is not accepted, the training skips that datasite and continues with the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_client.run_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_client.get_model_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the model can be evaluated on the test site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_client.run_evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
